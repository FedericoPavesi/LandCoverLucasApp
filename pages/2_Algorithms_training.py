import streamlit as st
from PIL import Image

st.markdown('# Algorithms training')

st.markdown('Before discussing classifiers training step results, an important premise must be done about randomness. Whole process contains many randomness sources, which will inevitably affect final results. Because we aim to provide a largely detailed overview of classifiers results, we will explore effects of such source of instability. Our decision is to assume random sample done on Lucas points, because of its high numerosity, is enough representative to affect rather little the stability of the estimates. What we do is to tune the model structure using a random split of the dataset into train, validation and test (respectively 60%, 20% and 20% of the dataset). Then we feed to all different possible model structures, both for random forest and MLP (1x1 and 3x3), train split of the dataset and we evaluate the performance of each on validation split. We choose model structure performing best in validation score (minimum loss for MLP and maximum accuracy for RF); the evaluation on test set is performed to check whether there is any visible instability.  Obtained an optimal model structure for each classification algorithm we test randomness by splitting again the dataset into train, validation and test as before, with the difference this time we are going to directly evaluate test scores. This is done ten times per classification algorithm and, for each trial, we save trained parameters. We then use scores to produce useful metrics to evaluate average accuracy and stability obtained by each classification algorithm such as average confusion matrix and standard deviation of each of its elements.')

st.markdown('### Random Forest')

st.markdown('Random forest is so widely recognized as a valid method to produce land-cover classification both Earth Engine and QGIS have an implemented routine to train a random forest classifier; anyway, we are not going to use them as they do not permit to explore some features we are interested in with sufficient fluidity. To boost the performance in terms of maximizing accuracy of the model, we launch the tuning step where we try different numerosity for number of trees, bootstrapped samples and number of regressors per tree. For 1x1 images, we find to be optimal a random forest with 100 trees, 2800 observations and 9 variables (out of 12) per bootstrapped sample. The classifier produces a test accuracy around 52/53%, considering that, because train, validation and test splits have the same numerosity between classes, a random classifier would have had an accuracy around 12.5% (as there are 8 land cover classes). The confusion matrix suggest accuracy is almost balanced between land cover categories. 3x3 images are subjected to the same tuning procedure, but training dataset is subject to flip and rotation augmentation (both for the tuning step and for the evaluation on ten different trials as described before). We find 100 trees, 2600 observations and 41 variables (out of 108 total) per bootstrapped sample to produce the highest accuracy. Accuracy and confusion matrix are almost the same as 1x1, meaning there is no improvement into switching from 1x1 to 3x3 training images when using a random forest algorithm.')

st.markdown('### Multi-Layer Perceptron')

st.markdown('Regarding multi-layer perceptron, we built an architecture using Tensorflow’s Keras  python library. Notice also in this case 3x3 images are subject to flip and rotations augmentation. Both models ended up performing best with the same structure, which is reported in figure 3.2, where on the left-hand side we have the architecture for 1x1 input (which has 12 spectral bands) and on the right-hand side for 3x3 input (with 3x3x12 = 108 spectral bands).')

path = 'C:/Users/drikb/Desktop/Tirocinio/Presentation_app/'

mlp1x1 = Image.open(path + 'MLP_1x1_structure.png')
mlp3x3 = Image.open(path + 'MLP_3x3_structure.png')

st.image([mlp1x1, mlp3x3], caption = ['MLP 1x1 structure', 'MLP 3x3 structure'], width = 250)

st.markdown('Wording ‘None’ means the architecture is ready to be fed whatever sample size, if for example we feed 4,000 images, this parameter will become 4,000. The architecture first passes input through a normalization layer, where it is divided by the theoretical maximum reflectance , 10,000. Then it is processed by three dense layers with respectively 128, 64 and 32 neurons, each with a ‘relu’ activation function (each one with an L1 and L2 regularization method with λ equal to 0.01). Before entering the final dense layer with 8 neurons (the numerosity of land cover classes), we have a dropout layer which drops 50% of the features. This is very useful because it reduces the tendency to overfit the training sample. The whole model is evaluated by categorical cross-entropy loss function, while the stochastic gradient descent is optimized via an ‘Adam’ optimizer. We run the process for 600 epochs with 300 samples as batch size. We know this number of epochs will surely overfit the training sample, so we will evaluate each time the validation loss, choosing the model with the lowest one. In order to choose this particular model structure, we passed different alternatives by adding or removing dense layers, by starting with more or less neurons, by modifying batch size and by deciding whether to add or not a final dropout layer. The final decision is for the model with the highest validation accuracy and the lowest numerosity of neurons. Such decision about the number of neurons is done in order to speed up as much as possible the prediction activity and it has priority over the number of epochs: in the tuning process between complexity of the model and number of epochs, as the model is intended to predict at the end large amounts of data , we enforced simplicity rather than the speed in which it reaches the minimum validation loss. Rationale is once we have trained the model, we can easily save its trained structure, this way it’s not very relevant how much time it needs to train. The most important part here is simplicity, such that we can perform prediction on large areas with reasonable computational time. In appendix 3.4 we find the evaluation of models on test dataset. Model with 1x1 input gives an accuracy around 57/58% while one with 3x3 input performs slightly better, reaching 60/61%. Class-specific accuracy (recall metric) is higher than random forest in both cases, but we observe MLP having higher prediction variability. Conversely to random forest approach, here we can appreciate an improvement in accuracy when switching from 1x1 to 3x3. Anyway, this improvement comes alongside with an increase in predictions variance.')